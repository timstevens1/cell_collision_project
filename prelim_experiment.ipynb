{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data/Formatted_Small_V5_segments.xlsx')\n",
    "data_n = pd.read_excel('Data/Small_V5_tracks.xlsx')\n",
    "data.columns = ['trash', 'id', 'time', 'x', 'y', 'z']\n",
    "data = data[['id', 'time', 'x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = sorted(list(set(data['id'])))\n",
    "times = sorted(list(set(data['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = []\n",
    "for n in data_n['Name']:\n",
    "    d = n.split('_')\n",
    "    if len(d) < 2:\n",
    "        types.append('TrackUnif')\n",
    "    else:\n",
    "        types.append(d[1])\n",
    "        \n",
    "t_list = set(types)\n",
    "t_dict = {t: i for i, t in enumerate(t_list)}\n",
    "type_ints = [t_dict[t] for t in types]\n",
    "data_n['Type'] = type_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189, 630)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_data = np.zeros((len(cells), 3*len(times)))\n",
    "format_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SYN': 0, 'DEAD': 1, 'UNINF': 2, 'MONO': 3}\n"
     ]
    }
   ],
   "source": [
    "print(t_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cell(cell, num_back=10):\n",
    "    \"\"\"\n",
    "    Creates a matrix of `num_back` length paths from `cell`s data.\n",
    "    If a cell has fewer than `num_back` time points, it discards the data.\n",
    "    If a cell has more than `num_back` time points, each `num_back` length\n",
    "    path constitutes one row in the returned matrix\n",
    "    \n",
    "    cell: the cell id\n",
    "    num_back: the path length\n",
    "    \n",
    "    returns: ds, the path matrix with 3*num_back columns\n",
    "    \"\"\"\n",
    "    d = data[data['id'] == cell]\n",
    "    ts = sorted(d['time'])\n",
    "    ds = np.zeros((len(ts)//num_back + 1, num_back*3 + 1))\n",
    "    for i, t in enumerate(ts):\n",
    "        if d[d['time'] == t][['x', 'y', 'z']].to_numpy().shape[0] > 1:\n",
    "            print(d[d['time'] == t][['x', 'y', 'z']].to_numpy().shape)\n",
    "            continue\n",
    "        ds[i//num_back, i%num_back*3:i%num_back*3+3] = d[d['time'] == t][['x', 'y', 'z']].to_numpy()\n",
    "    for i in range(ds.shape[0]):\n",
    "        ofs = ds[i, 0:3]\n",
    "        for j in range(num_back):\n",
    "            ds[i, 3*j:3*j+3] = ds[i, 3*j:3*j+3] #- ofs\n",
    "    ds[:,-1] = data_n[(data_n['Id'] == cell)]['Type']\n",
    "    if ds[-1,-2] == 0:\n",
    "        return ds[:-1, :]\n",
    "    return ds\n",
    "        \n",
    "    \n",
    "#format_cell(1262868), data[data['id'] == 1262868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a the matrix of paths to train models on\n",
    "\n",
    "num_back = 10\n",
    "cell_arrays = []\n",
    "for c in cells:\n",
    "    times = data[data['id'] == c]['time']\n",
    "    r = max(times) - min(times)\n",
    "    if r < 4*num_back:\n",
    "        continue\n",
    "    cell_arrays.append(format_cell(c, num_back))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11027, 31)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmt_data = np.vstack(cell_arrays)\n",
    "fmt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9584, 31)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = fmt_data[:,-1] != t_dict['DEAD']\n",
    "fmt_data = fmt_data[mask, :]\n",
    "fmt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the last point in the path. X is the first num_back - 1 points\n",
    "# X,y = fmt_data[:, :-4], fmt_data[:, -3:-1]\n",
    "\n",
    "X, y = fmt_data[:, :-1], fmt_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)\n",
    "y = y == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.hstack((x_train, np.atleast_2d(y_train).T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_os = train[np.where(train[:, -1] == 0)]\n",
    "t_3s = train[np.where(train[:, -1] == 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.vstack((train, t_os, t_3s, t_os, t_3s, t_os, t_3s, t_os, t_3s))\n",
    "np.random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train[:, :-1], train[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = RandomForestClassifier(oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(oob_score=True)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.98      0.97       278\n",
      "        True       1.00      0.99      1.00      2118\n",
      "\n",
      "    accuracy                           0.99      2396\n",
      "   macro avg       0.98      0.99      0.98      2396\n",
      "weighted avg       0.99      0.99      0.99      2396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = rgr.predict(x_test)\n",
    "rgr.score(x_test, y_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x7f9f80500750>"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(rgr, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9344741235392321, 0.06552587646076795)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = dtr.predict(x_test)\n",
    "dtr.score(x_test,y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7671381936887922, 0.30431628581791803)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "preds = lr.predict(x_test)\n",
    "lr.score(x_test, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "n_features = 30\n",
    "n_classes=len(t_list)\n",
    "training_dataset = TensorDataset(torch.from_numpy(x_train).float(), \n",
    "                                 torch.from_numpy(y_train).long())\n",
    "train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "testing_dataset = TensorDataset(torch.from_numpy(x_test).float(), \n",
    "                                torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, n_hidden=64, p_dropout=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden, bias=True)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc4 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc5 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc6 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc7 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc8 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc9 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc10 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc11 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc12 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc13 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc14 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc15 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc16 = nn.Linear(n_hidden, n_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = nn.ReLU()(self.fc4(x))\n",
    "        #x = nn.ReLU()(self.fc5(x))\n",
    "        #x = nn.ReLU()(self.fc6(x))\n",
    "        #x = nn.ReLU()(self.fc7(x))\n",
    "        #x = nn.ReLU()(self.fc8(x))\n",
    "        #x = nn.ReLU()(self.fc9(x))\n",
    "        #x = nn.ReLU()(self.fc10(x))\n",
    "        #x = nn.ReLU()(self.fc11(x))\n",
    "        #x = nn.ReLU()(self.fc12(x))\n",
    "        #x = nn.ReLU()(self.fc13(x))\n",
    "        #x = nn.ReLU()(self.fc14(x))\n",
    "        #x = nn.ReLU()(self.fc15(x))\n",
    "        x = self.fc16(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_accuracy(model, test_loader, lf=nn.NLLLoss()):\n",
    "    lossies = []\n",
    "    accs = []\n",
    "    #grab a batch from the test loader\n",
    "    with torch.no_grad():\n",
    "        for examples, labels in test_loader:\n",
    "            torch.cuda.empty_cache()\n",
    "            outputs = model.forward(examples)\n",
    "            lossies.append(lf(torch.squeeze(outputs), torch.squeeze(labels)).item())\n",
    "\n",
    "            #for each output in the batch, check if the label is correct\n",
    "            preds = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "            labels = labels.detach().numpy()\n",
    "            accuracy = (preds == labels).mean()\n",
    "            accs.append(accuracy)\n",
    "\n",
    "    loss = sum(lossies)/len(lossies)\n",
    "    acc = sum(accs)/len(accs)\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=20):\n",
    "    # reset the model\n",
    "    model = Classifier(n_features=n_features, n_classes=len(set(y_test)))\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model.forward(x_batch_train)\n",
    "            loss = criterion(outputs, y_batch_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().numpy())\n",
    "    \n",
    "        if epoch % 10 == 0:\n",
    "            print(np.mean(losses))\n",
    "            print(loader_accuracy(model, test_loader))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0960009\n",
      "(0.1948784722222222, 0.7554156846470303)\n",
      "0.6623714\n",
      "(0.2608506944444444, 0.809357742468516)\n",
      "0.65122664\n",
      "(0.4887152777777778, 0.7224977413813273)\n",
      "0.6269263\n",
      "(0.4370659722222222, 0.756029811170366)\n",
      "0.60217303\n",
      "(0.5221354166666666, 0.6522340774536133)\n",
      "0.5870463\n",
      "(0.5434027777777778, 0.6662152740690443)\n",
      "0.56847405\n",
      "(0.6380208333333334, 0.5762496656841702)\n",
      "0.54774904\n",
      "(0.5260416666666666, 0.7471619976891412)\n",
      "0.5377645\n",
      "(0.4175347222222222, 0.8324476546711392)\n",
      "0.51795805\n",
      "(0.6176215277777778, 0.6197690036561754)\n",
      "0.49853438\n",
      "(0.5720486111111112, 0.6844008631176419)\n",
      "0.47058955\n",
      "(0.6983506944444444, 0.5224905874994066)\n",
      "0.45636255\n",
      "(0.7400173611111112, 0.49046015408304)\n",
      "0.41842306\n",
      "(0.7287326388888888, 0.4814263615343306)\n",
      "0.40186334\n",
      "(0.7265625, 0.48826080560684204)\n",
      "0.39234385\n",
      "(0.7552083333333334, 0.4611557920773824)\n",
      "0.35715273\n",
      "(0.7638888888888888, 0.48768897851308185)\n",
      "0.35385692\n",
      "(0.6853298611111112, 0.6053784886995951)\n",
      "0.34430552\n",
      "(0.7964409722222222, 0.3951825698216756)\n",
      "0.3596293\n",
      "(0.8368055555555556, 0.35027337074279785)\n"
     ]
    }
   ],
   "source": [
    "m = train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = m(torch.Tensor(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(vals,dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.827212020033389"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[278, 2118, 0, 0]"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sum(y_test == i) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885642737896494"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2129/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.79      0.52       278\n",
      "        True       0.97      0.83      0.89      2118\n",
      "\n",
      "    accuracy                           0.83      2396\n",
      "   macro avg       0.68      0.81      0.71      2396\n",
      "weighted avg       0.90      0.83      0.85      2396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

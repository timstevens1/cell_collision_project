{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('Data/formatted_Small_V5_segments.xlsx')\n",
    "data_n = pd.read_excel('Data/Small_V5_tracks.xlsx')\n",
    "data.columns = ['row_idx', 'id', 'time', 'x', 'y', 'z']\n",
    "data = data[['id', 'time', 'x', 'y', 'z']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = sorted(list(set(data['id'])))\n",
    "times = sorted(list(set(data['time'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SYN', 'DEAD', 'UNINF', 'MONO'}\n"
     ]
    }
   ],
   "source": [
    "types = [n.split('_')[1] for n in data_n['Name']]\n",
    "t_list = set(types)\n",
    "t_dict = {t: i for i, t in enumerate(t_list)}\n",
    "type_ints = [t_dict[t] for t in types]\n",
    "data_n['Type'] = type_ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1189, 630)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_data = np.zeros((len(cells), 3*len(times)))\n",
    "format_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_cell(cell, num_back=10):\n",
    "    \"\"\"\n",
    "    Creates a matrix of `num_back` length paths from `cell`s data.\n",
    "    If a cell has fewer than `num_back` time points, it discards the data.\n",
    "    If a cell has more than `num_back` time points, each `num_back` length\n",
    "    path constitutes one row in the returned matrix\n",
    "    \n",
    "    cell: the cell id\n",
    "    num_back: the path length\n",
    "    \n",
    "    returns: ds, the path matrix with 3*num_back columns\n",
    "    \"\"\"\n",
    "    d = data[data['id'] == cell]\n",
    "    ts = sorted(d['time'])\n",
    "    ds = np.zeros((len(ts)//num_back + 1, num_back*3 + 1))\n",
    "    for i, t in enumerate(ts):\n",
    "        ds[i//num_back, i%num_back*3:i%num_back*3+3] = d[d['time'] == t][['x', 'y', 'z']].to_numpy()\n",
    "    for i in range(ds.shape[0]):\n",
    "        ofs = ds[i, 0:3]\n",
    "        for j in range(num_back):\n",
    "            ds[i, 3*j:3*j+3] = ds[i, 3*j:3*j+3] #- ofs\n",
    "    ds[:,-1] = data_n[(data_n['Id'] == cell)]['Type']\n",
    "    if ds[-1,-2] == 0:\n",
    "        return ds[:-1, :]\n",
    "    return ds\n",
    "        \n",
    "    \n",
    "#format_cell(1262868), data[data['id'] == 1262868]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a the matrix of paths to train models on\n",
    "\n",
    "num_back = 10\n",
    "cell_arrays = []\n",
    "for c in cells:\n",
    "    times = data[data['id'] == c]['time']\n",
    "    r = max(times) - min(times)\n",
    "    if r < 4*num_back:\n",
    "        continue\n",
    "    cell_arrays.append(format_cell(c, num_back))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11027, 31)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmt_data = np.vstack(cell_arrays)\n",
    "fmt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9584, 31)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = fmt_data[:,-1] != t_dict['DEAD']\n",
    "fmt_data = fmt_data[mask, :]\n",
    "fmt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is the last point in the path. X is the first num_back - 1 points\n",
    "# X,y = fmt_data[:, :-4], fmt_data[:, -3:-1]\n",
    "X, y = fmt_data[:, :-1], fmt_data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgr = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.929465776293823, 0.14816360601001669)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = rgr.predict(x_test)\n",
    "rgr.score(x_test, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeClassifier()\n",
    "dtr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9010851419031719, 0.2149415692821369)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = dtr.predict(x_test)\n",
    "dtr.score(x_test,y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.get_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tim/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8868948247078464, 0.21076794657762937)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "preds = lr.predict(x_test)\n",
    "lr.score(x_test, y_test), mse(preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "n_features = 30\n",
    "n_classes=len(t_list)\n",
    "training_dataset = TensorDataset(torch.from_numpy(x_train).float(), \n",
    "                                 torch.from_numpy(y_train).long())\n",
    "train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "\n",
    "testing_dataset = TensorDataset(torch.from_numpy(x_test).float(), \n",
    "                                torch.from_numpy(y_test).long())\n",
    "test_loader = DataLoader(testing_dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_features, n_classes, n_hidden=128, p_dropout=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(n_features, n_hidden, bias=True)\n",
    "        self.fc2 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc3 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc4 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc5 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc6 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc7 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc8 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc9 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc10 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc11 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc12 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc13 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc14 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc15 = nn.Linear(n_hidden, n_hidden, bias=True)\n",
    "        self.fc16 = nn.Linear(n_hidden, n_classes, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = nn.ReLU()(self.fc3(x))\n",
    "        x = nn.ReLU()(self.fc4(x))\n",
    "        x = nn.ReLU()(self.fc5(x))\n",
    "        x = nn.ReLU()(self.fc6(x))\n",
    "        x = nn.ReLU()(self.fc7(x))\n",
    "        #x = nn.ReLU()(self.fc8(x))\n",
    "        #x = nn.ReLU()(self.fc9(x))\n",
    "        #x = nn.ReLU()(self.fc10(x))\n",
    "        #x = nn.ReLU()(self.fc11(x))\n",
    "        #x = nn.ReLU()(self.fc12(x))\n",
    "        #x = nn.ReLU()(self.fc13(x))\n",
    "        #x = nn.ReLU()(self.fc14(x))\n",
    "        #x = nn.ReLU()(self.fc15(x))\n",
    "        x = self.fc16(x)\n",
    "        x = torch.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader_accuracy(model, test_loader, lf=nn.NLLLoss()):\n",
    "    lossies = []\n",
    "    accs = []\n",
    "    #grab a batch from the test loader\n",
    "    with torch.no_grad():\n",
    "        for examples, labels in test_loader:\n",
    "            torch.cuda.empty_cache()\n",
    "            outputs = model.forward(examples)\n",
    "            lossies.append(lf(torch.squeeze(outputs), torch.squeeze(labels)).item())\n",
    "\n",
    "            #for each output in the batch, check if the label is correct\n",
    "            preds = np.argmax(outputs.detach().numpy(), axis=1)\n",
    "            labels = labels.detach().numpy()\n",
    "            accuracy = (preds == labels).mean()\n",
    "            accs.append(accuracy)\n",
    "\n",
    "    loss = sum(lossies)/len(lossies)\n",
    "    acc = sum(accs)/len(accs)\n",
    "\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=20):\n",
    "    # reset the model\n",
    "    model = Classifier(n_features=n_features, n_classes=n_classes)\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        losses = []\n",
    "\n",
    "        for x_batch_train, y_batch_train in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model.forward(x_batch_train)\n",
    "            loss = criterion(outputs, y_batch_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.detach().numpy())\n",
    "    \n",
    "        if epoch % 10 == 0:\n",
    "            print(np.mean(losses))\n",
    "            print(loader_accuracy(model, test_loader))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49391037\n",
      "(0.8880208333333334, 0.46231256590949166)\n",
      "0.41077343\n",
      "(0.8880208333333334, 0.4008244110478295)\n",
      "0.39584282\n",
      "(0.8897569444444444, 0.404458483060201)\n",
      "0.37488395\n",
      "(0.8910590277777778, 0.37450043360392254)\n",
      "0.3674578\n",
      "(0.8919270833333334, 0.3675025635295444)\n",
      "0.34624973\n",
      "(0.88671875, 0.3611697455247243)\n",
      "0.32526198\n",
      "(0.8932291666666666, 0.35570699638790554)\n",
      "0.31076398\n",
      "(0.89453125, 0.3329940173361037)\n",
      "0.31170517\n",
      "(0.890625, 0.3628953860865699)\n",
      "0.30369392\n",
      "(0.8940972222222222, 0.33491947915818954)\n",
      "0.2766269\n",
      "(0.890625, 0.33552850948439705)\n",
      "0.26931438\n",
      "(0.8953993055555556, 0.3172774248652988)\n",
      "0.26031822\n",
      "(0.8958333333333334, 0.34970776240030926)\n",
      "0.28884655\n",
      "(0.8936631944444444, 0.3364178505208757)\n",
      "0.2229385\n",
      "(0.89453125, 0.37384254071447587)\n",
      "0.21852048\n",
      "(0.8980034722222222, 0.3791923721631368)\n",
      "0.21190755\n",
      "(0.89453125, 0.397639446788364)\n",
      "0.19883701\n",
      "(0.8953993055555556, 0.39260249336560565)\n",
      "0.21242496\n",
      "(0.9006076388888888, 0.41020987762345207)\n",
      "0.20520644\n",
      "(0.8897569444444444, 0.3940731982390086)\n"
     ]
    }
   ],
   "source": [
    "m = train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = m(torch.Tensor(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.argmax(vals,dim=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8939899833055092"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds == y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[71, 0, 2129, 196]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sum(y_test == i) for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885642737896494"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2129/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
